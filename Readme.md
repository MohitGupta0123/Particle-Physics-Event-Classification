# ðŸ§ª Particle Physics Event Classification

Distinguishing rare **Higgs-boson signal events** from overwhelming **background noise** in protonâ€“proton collisions at CERN.
This project builds a robust machine-learning pipeline that leverages **ensemble learning (stacking)** to classify events using rich kinematic features from detector data.

---

## ðŸ“‚ Project Structure

```
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Artifacts
â”‚   â”œâ”€â”€ Best_artifacts.pkl
â”‚   â””â”€â”€ inference_pipeline.pkl
â”œâ”€â”€ Baseline1.ipynb
â”œâ”€â”€ Baseline2.ipynb
â”œâ”€â”€ Data
â”‚   â”œâ”€â”€ Dataset.csv
â”‚   â”œâ”€â”€ Test.csv
â”‚   â”œâ”€â”€ Train.csv
â”‚   â””â”€â”€ Transformed_Dataset.csv
â”œâ”€â”€ EDA.ipynb
â”œâ”€â”€ Mohit_Gupta.pdf
â”œâ”€â”€ Mohit_Gupta.pptx
â”œâ”€â”€ Readme.md
â””â”€â”€ catboost_info
    â”œâ”€â”€ catboost_training.json
    â”œâ”€â”€ learn
    â”‚   â””â”€â”€ events.out.tfevents
    â”œâ”€â”€ learn_error.tsv
    â””â”€â”€ time_left.tsv
```

---

## âš™ï¸ Methodology

### ðŸ”¹ Preprocessing

* Handle missing values (`ApplyTransformDataset`):

  * Replace infinite values with NaN
  * Impute with mean/median depending on outliers
  * Cap outliers using **z-score clipping**
* Drop irrelevant columns (`ColumnDropper`)

### ðŸ”¹ Model Architecture

* **Base Learners**:

  * XGBoost, LightGBM, CatBoost
  * Parameters: `n_estimators=700`, `max_depth=7`, `learning_rate=0.1`
* **Stacking Ensemble**:

  * Combines base learners using **Logistic Regression** as a meta-learner
  * Uses `predict_proba` outputs as features
  * 5-fold cross-validation

### ðŸ”¹ Training Setup

* **Dataset**:

  * Total: **200,000 events**
  * Signal (s): **68,534**
  * Background (b): **131,466**
  * Features used: **18** (from original 30)
* **Threshold Tuning**: 0.49 (balance recall vs. precision)

---

## ðŸ“Š Results

### âœ… Training Set (200k samples)

* **Accuracy**: `0.863`
* **ROC-AUC**: `0.934`
* Strong separation between signal & background.

### ðŸ“¦ Cross-Validation (CV folds)

* **Accuracy**: `0.838 Â± 0.002`
* **ROC-AUC**: `0.908 Â± 0.002`

### ðŸ§ª Test Set (50k samples)

* **Accuracy**: `0.838`
* **ROC-AUC**: `0.907`

ðŸ” **Observation**:

* Good generalization; mild overfitting (training slightly higher).
* More **false negatives** than false positives â†’ threshold tuning could improve recall.

---

## ðŸ“Œ How to Run

### 1ï¸âƒ£ Train & Save Pipeline

```bash
Run Baseline2.ipynb
```

This will:

* Preprocess the dataset
* Train base learners + stacking ensemble
* Save pipeline as `artifacts/inference_pipeline.pkl`

### 2ï¸âƒ£ Inference on New Data

```python
import pickle
import pandas as pd

with open("artifacts/inference_pipeline.pkl", "rb") as f:
    saved = pickle.load(f)

pipe = saved["pipeline"]
threshold = saved["threshold"]

df_new = pd.read_csv("Data/Test.csv")
y_prob = pipe.predict_proba(df_new)[:, 1]
y_pred = (y_prob >= threshold).astype(int)
```

---

## ðŸš€ Future Work

* Apply **calibration** & **regularization** to reduce overfitting.
* Explore **deep learning models** for richer feature interactions.
* Optimize threshold for better **recall of rare signal events**.

---